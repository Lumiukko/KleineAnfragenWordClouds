{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kleine Anfragen WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "import os\n",
    "from nltk.stem.snowball import GermanStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(\"E:\\\\wordclouds\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to create the bag of words\n",
    "\n",
    "This function takes the rows from the database and creates the bag of words (i.e. counts the occurrences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_bow(rows, use_stemmer=False, use_contents=False):\n",
    "    \n",
    "    if use_stemmer:\n",
    "        stemmer = GermanStemmer()\n",
    "        stemmer._GermanStemmer__step3_suffixes = () # Step 3 removes too much.\n",
    "        stemmer._GermanStemmer__step1_suffixes = ('ern', 'em', 'er', 'en', 'es', 's')\n",
    "    \n",
    "    local_stop_words = []\n",
    "    for sw in stop_words:\n",
    "        if use_stemmer:\n",
    "            local_stop_words.append(stemmer.stem(sw))\n",
    "        else:\n",
    "            local_stop_words.append(sw)\n",
    "    \n",
    " \n",
    "    bow = Counter([])\n",
    "\n",
    "    for r in rows:\n",
    "        txt = r[1] # Title\n",
    "        \n",
    "        if use_contents:\n",
    "            txt += \" \" + r[2]\n",
    "        \n",
    "        for sp in stop_punct:\n",
    "            txt = txt.replace(sp, \" \")\n",
    "        txt = txt.split()\n",
    "\n",
    "        tokens = []\n",
    "        \n",
    "        \n",
    "        for w in txt:\n",
    "            token = w.strip()\n",
    "            token = token[0].upper() + token[1:]\n",
    "            if use_stemmer:\n",
    "                token = stemmer.stem(token)\n",
    "                \n",
    "            if len(token) > 2 and token.lower() not in local_stop_words:\n",
    "                illegal_prefix = False\n",
    "                for sp in stop_prefixes:\n",
    "                    if token.lower().startswith(sp):\n",
    "                        illegal_prefix = True\n",
    "                \n",
    "                if not illegal_prefix:\n",
    "                    tokens.append(token)\n",
    "        \n",
    "        bow += Counter(tokens)\n",
    "\n",
    "\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the PostgreSQL DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#c.close()\n",
    "#conn.close()\n",
    "conn = psycopg2.connect(\"dbname=kleineanfragen user=postgres password=ayayay\")\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = [\"Baden-Württemberg\", \"Bayern\", \"Berlin\", \"Brandenburg\", \"Bremen\", \"Hamburg\", \"Hessen\",\n",
    "          \"Mecklenburg-Vorpommern\", \"Niedersachsen\", \"Nordrhein-Westfalen\", \"Rheinland-Pfalz\",\n",
    "          \"Saarland\", \"Sachsen\", \"Sachsen-Anhalt\", \"Schleswig-Holstein\", \"Thüringen\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The stop words that will be filtered out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = [\"aber\", \"als\", \"am\", \"an\", \"auch\", \"auf\", \"aus\", \"bei\", \"bin\", \"bis\", \"bist\", \"da\",\n",
    "              \"dadurch\", \"daher\", \"darum\", \"das\", \"daß\", \"dass\", \"dein\", \"deine\", \"dem\", \"den\",\n",
    "              \"der\", \"des\", \"dessen\", \"deshalb\", \"die\", \"dies\", \"dieser\", \"dieses\", \"doch\", \"dort\", \n",
    "              \"du\", \"durch\", \"ein\", \"eine\", \"einem\", \"einen\", \"einer\", \"eines\", \"er\", \"es\", \"euer\", \n",
    "              \"eure\", \"für\", \"hatte\", \"hatten\", \"hattest\", \"hattet\", \"hier\", \"hinter\", \"ich\", \"ihr\",\n",
    "              \"ihre\", \"im\", \"in\", \"ist\", \"ja\", \"jede\", \"jedem\", \"jeden\", \"jeder\", \"jedes\", \"jener\",\n",
    "              \"jenes\", \"jetzt\", \"kann\", \"kannst\", \"können\", \"könnt\", \"machen\", \"mein\", \"meine\",\n",
    "              \"mit\", \"muß\", \"mußt\", \"musst\", \"müssen\", \"müßt\", \"nach\", \"nachdem\", \"nein\", \"nicht\", \n",
    "              \"nun\", \"oder\", \"seid\", \"sein\", \"seine\", \"sich\", \"sie\", \"sind\", \"soll\", \"sollen\",\n",
    "              \"sollst\", \"sollt\", \"sonst\", \"soweit\", \"sowie\", \"und\", \"unser\", \"unsere\", \"unter\",\n",
    "              \"vom\", \"von\", \"vor\", \"wann\", \"warum\", \"was\", \"weiter\", \"weitere\", \"wenn\", \"wer\",\n",
    "              \"werde\", \"werden\", \"werdet\", \"weshalb\", \"wie\", \"wieder\", \"wieso\", \"wir\", \"wird\",\n",
    "              \"wirst\", \"wo\", \"woher\", \"wohin\", \"zu\", \"zum\", \"zur\", \"über\", \"a\", \"about\", \"above\",\n",
    "              \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"aren't\", \"as\",\n",
    "              \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\",\n",
    "              \"by\", \"can't\", \"cannot\", \"could\", \"couldn't\", \"did\", \"didn't\", \"do\", \"does\", \"doesn't\",\n",
    "              \"doing\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\",\n",
    "              \"hadn't\", \"has\", \"hasn't\", \"have\", \"haven't\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\",\n",
    "              \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\",\n",
    "              \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"isn't\", \"it\", \"it's\", \n",
    "              \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"mustn't\", \"my\", \"myself\", \"no\", \"nor\",\n",
    "              \"not\", \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\",\n",
    "              \"out\", \"over\", \"own\", \"same\", \"shan't\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\",\n",
    "              \"shouldn't\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\",\n",
    "              \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\",\n",
    "              \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
    "              \"very\", \"was\", \"wasn't\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"weren't\",\n",
    "              \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\",\n",
    "              \"whom\", \"why\", \"why's\", \"with\", \"won't\", \"would\", \"wouldn't\", \"you\", \"you'd\", \"you'll\",\n",
    "              \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\"]\n",
    "\n",
    "for s in states:\n",
    "    stop_words.append(s.lower())\n",
    "\n",
    "stop_words += [\"januar\", \"februar\", \"märz\", \"april\", \"mai\", \"juni\", \"juli\",\n",
    "               \"august\", \"september\", \"oktober\", \"november\", \"dezember\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop prefixes. Every word starting as one of these will be filtered out as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_prefixes = [\"bayerisch\", \"bremer\", \"bremisch\", \"hessisch\", \"mecklenburg-vorpomm\", \"niedersächs\",\n",
    "                 \"nordrhein-westfäl\", \"nordrhein-westfal\", \"rheinland-pfälz\", \"saarländ\", \"sächsisch\",\n",
    "                 \"thüring\", \"anfrage\", \"nachfrage\"]\n",
    "\n",
    "for s in states:\n",
    "    stop_prefixes.append(s.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation that will be replaced by a blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_punct = \"!/\\\\()*+,./:;?[]^_`\\{|\\}~\\\"'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_query(party=\"all\", region=False):\n",
    "    # Careful, region is case sensitive!\n",
    "\n",
    "    query = \"select papers.id, title, contents, originator_type, organizations.name, bodies.name\\n\"\n",
    "    query += \" from papers\\n\"\n",
    "    query += \" inner join paper_originators on papers.id = paper_originators.paper_id\\n\"\n",
    "    query += \" inner join organizations on originator_id = organizations.id\\n\"\n",
    "    query += \" inner join bodies on papers.body_id = bodies.id\\n\"\n",
    "    query += \" where originator_type = 'Organization'\\n\"\n",
    "    \n",
    "    # If party is specified, add condition to query.\n",
    "    \n",
    "    if party == \"cdu\":\n",
    "        query += \" and (organizations.id = 11 or organizations.id = 22 or organizations.id = 237)\"\n",
    "\n",
    "    elif party == \"spd\":\n",
    "        query += \" and (organizations.id = 2)\"\n",
    "        \n",
    "    elif party == \"linke\":\n",
    "        query += \" and (organizations.id = 14)\"\n",
    "\n",
    "    elif party == \"afd\":\n",
    "        query += \" and (organizations.id = 39 or organizations.id = 238)\"\n",
    "    \n",
    "    elif party == \"grüne\":\n",
    "        query += \" and (organizations.id = 1 or organizations.id = 237)\"\n",
    "        \n",
    "    elif party == \"piraten\":\n",
    "        query += \" and organizations.id = 13\"\n",
    "        \n",
    "    elif party == \"fdp\":\n",
    "        query += \" and (organizations.id = 31 or organizations.id = 151)\"\n",
    "        \n",
    "    elif party == \"npd\":\n",
    "        query += \" and (organizations.id = 30)\"\n",
    "        \n",
    "    elif party == \"fw\":\n",
    "        query += \" and (organizations.id = 3  or organizations.id = 136)\"\n",
    "            \n",
    "    elif party == \"fraktionslos\":\n",
    "        query += \" and (organizations.id = 15)\"\n",
    "        \n",
    "    \n",
    "        \n",
    "    # Add region condition, or use all.\n",
    "\n",
    "    if region:\n",
    "        query += \" and bodies.name = '{}'\".format(region)\n",
    "    else:\n",
    "        region = \"all\"\n",
    "\n",
    "    query += \";\"\n",
    "\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the cloud!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_word_cloud(party=\"all\", region=False, use_stemmer = False, use_contents = False):\n",
    "    query = build_query(party=party, region=region)\n",
    "    c.execute(query)\n",
    "    rows = c.fetchall()\n",
    "    print(\"{} + {} = {} rows.\".format(party, region, len(rows)))\n",
    "    \n",
    "    bow = make_bow(rows, use_stemmer=use_stemmer, use_contents=use_contents)\n",
    "    \n",
    "    if not region or region == \"Bundestag\":\n",
    "        ger_mask = plt.imread(\"./region_shapes/ger.jpg\")\n",
    "    else:\n",
    "        ger_mask = plt.imread(\"./region_shapes/{}.jpg\".format(region))\n",
    "        \n",
    "    wc = WordCloud(background_color=\"black\", mask=ger_mask, stopwords=stop_words,\n",
    "                   max_words=300).generate_from_frequencies(list(bow.items()))\n",
    "    \n",
    "\n",
    "    #plt.figure(figsize=(20, 28))\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    fig = plt.imshow(wc)\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    plt.savefig(\"./output/wordcloud_{}_{}_{}_{}.jpg\".format(\"all\" if not region else region, party, \"stem\" if use_stemmer else \"nostem\", \"tc\" if use_contents else \"tonly\"),\n",
    "                bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate all the clouds!\n",
    "\n",
    "Warning: can take some time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orgs = [\"cdu\", \"spd\", \"linke\", \"grüne\", \"fw\", \"fraktionslos\", \"afd\", \"npd\", \"fdp\", \"piraten\", \"all\"]\n",
    "regions = states[:]\n",
    "regions.append(False)\n",
    "regions.append(\"Bundestag\")\n",
    "\n",
    "for o in orgs:\n",
    "    create_word_cloud(o, False)\n",
    "    \n",
    "for r in regions:\n",
    "    create_word_cloud(\"all\", r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
